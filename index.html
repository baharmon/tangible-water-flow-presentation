<section>
<h3 style="color: #888"><a href="http://www.isprs2016-prague.com/">ISPRS 2016</a></h3>
<h1 style="margin-top: 0.5em">Tangible Landscape</h1>
<h2 style="margin-top: 0.5em">Cognitively grasping the flow of water</h2>
<h4>Brendan Harmon, Anna Petrasova, Vaclav Petras, Helena Mitasova, &amp; Ross Meentemeyer</h4>
<img height="100px" style="margin-top: 2em" src="img/cgaBlack.png">
</section>

<!-- Tangible Landscape -->
<section data-background="img/tangible_landscape.jpg">
<h1 class="shadow">Tangible Landscape</h1>
<h3 class="shadow">A tangible user interface powered by open source GIS</h3>
<img height="150px" src="img/logo_black.png">
</section>

<!-- Near real time interaction -->
<section>
<h2>Tanigble interaction with GIS</h2>
<video  data-autoplay width="90%" style="margin-top: 1em" controls>
<source src="img/tl_dam.mp4" type="video/mp4">
Your browser does not support the video tag.
</video>
<p>With Tangible Landscape you can hold a GIS in your hands - feeling the shape of the earth, sculpting its topography, and directing the flow of water.</p>
</section>

<!-- History -->
<section>
<h2>History</h2>
<img height="250px" src="img/illuminating_clay.png">
<img height="250px" src="img/tangeoms_2.jpg">
<p>An evolution of <b>Illuminating Clay</b> and the <b>Tangible Geospatial Modeling System</b></p>
<p style="font-size:0.75em"><a href="http://tmg-trackr.media.mit.edu/publishedmedia/Papers/249-Illuminating%20Clay%20A%20Tangible/Published/PDF">Piper, Ben, Carlo Ratti, and Hiroshi Ishii. 2002. “Illuminating Clay: A Tangible Interface with Potential GRASS Applications.” In Proceedings of the Open Source GIS - GRASS Users Conference 2002. Trento, Italy.</a></p>
<p style="font-size:0.75em">Image source: <a href="http://tangible.media.mit.edu/project/illuminating-clay/">MIT Media Lab</a></p>
<p style="font-size:0.75em"><a href="http://baharmon.github.io/publications/tangible_geospatial_modeling.pdf">L. Tateosian, H. Mitasova, B. A. Harmon, B. Fogleman, K. Weaver, and R. S. Harmon, “TanGeoMS: tangible geospatial modeling system.,” IEEE Trans. Vis. Comput. Graph., vol. 16, no. 6, pp. 1605–12, 2010.</a></p>
</section>

<!-- How it works -->
<section>
<h2>How-it-works</h2>
<img style="margin-top: 1em" height="500px" src="img/system_schema.png">
<p>Tangible Landscape couples a digital and a physical model through a continuous cycle of 3D scanning, geospatial modeling, and projection</p>
</section>

<!-- Features -->
<section>
<h2>Features</h2>
<video  data-autoplay width="90%" style="margin-top: 0.5em" controls>
<source src="img/tl_immersion.mp4" type="video/mp4">
Your browser does not support the video tag.
</video>
<p>A collaborative environment for tangible freeform modeling, object detection, real-time geospatial analytics, 3D rendering, and immersion / VR</p>
</section>

<!-- Science with Tangible Landscape -->
<section>
<h2>Intuitive scientific modeling with Tangible Landscape</h2>
<img width="25%" src="img/subsurface_1.jpg">
<img width="25%" src="img/subsurface_2.jpg">
<img width="40.55%" src="img/subsurface_3.jpg">
<p>Tangible Landscape is designed to enable a rapid iterative process of observation, hypothesizing, testing, and inference</p>
</section>

<!-- Experiment -->

<!-- Research questions -->


<!-- Design | Methods -->



<!-- Results -->

<section>
<h2>Elevation</h2>
<img width="30%" src="img/results/render_3d/dem.png">
<img width="30%" src="img/results/render_3d/mean_dem_1.png">
<img width="30%" src="img/results/render_3d/mean_dem_2.png">
<p><b>a)</b> The reference landscape, <b>b)</b> the mean of digitally sculpted models, <b>c)</b> and the mean of tangibly sculpted models</p>
</section>

<section>
<h2>Water flow</h2>
<img width="30%" src="img/results/render_3d/depth.png">
<img width="30%" src="img/results/render_3d/mean_depth_1.png">
<img width="30%" src="img/results/render_3d/mean_depth_2.png">
<p>Water depth on <b>a)</b> the reference landscape, <b>b)</b> the mean of digitally sculpted models, <b>c)</b> and the mean of tangibly sculpted models</p>
</section>

<section>
<h2>Difference in water flow</h2>
<img width="30%" src="img/results/render_3d/diff.png">
<img width="30%" src="img/results/render_3d/mean_diff_1.png">
<img width="30%" src="img/results/render_3d/mean_diff_2.png">
<p>The difference between the reference water depth and <b>a)</b> itself, <b>b)</b> the mean water depth of digitally sculpted models, <b>c)</b> and the mean water depth of tangibly sculpted models</p>
</section>

<!--
<section>
<h2>Minimum distance</h2>
<img width="30%" src="img/results/render_3d/flow_distance_1.png">
<img width="30%" src="img/results/render_3d/flow_distance_2.png">
<p>The minimum distance between points with concentrated flow on the reference landscape and <b>a)</b> the mean of digitally sculpted models <b>b)</b> and the mean of tangibly sculpted models</p>
</section>
-->

<section>
<h2>Depressions</h2>
<img width="30%" src="img/results/render_3d/depressions.png">
<img width="30%" src="img/results/render_3d/mean_depressions_1.png">
<img width="30%" src="img/results/render_3d/mean_depressions_2.png">
<p>The depth of depressions in <b>a)</b> the reference landscape, <b>b)</b> the mean of digitally sculpted models, <b>c)</b> and the mean of tangibly sculpted models</p>
</section>

<section>
<h2>Percent cells with depressions</h2>
<table>
<tr><th>Exercise</th><th>Cells (3 sq ft)</th></tr>
<tr><td>Reference</td><td>0%</td></tr>
<tr><td>Digital</td><td>44%</td></tr>
<tr><td>Tangible</td><td>17.66%</td></tr>
</table>
</section>

<!-- Findings -->
<section>
<h2>Findings</h2>
<h4>Tangible modeling</h4>
<p>
<ul>
  <li>Participants typically focused on directing water into streams,
    but did not tend focus on directing a continuous flow downstream.</li>
  <li>Participants graded smoother slopes with fewer depressions
    whose curvature directed water towards channels, concentrating it in streams.
    They, however, did not tend to grade the channels to continuously slope downstream.</li>
  <li>While participants performance improved substantially,
    the pervasive presence of depressions in the stream channels
    in both exercises demonstrates that participants
    did not fully understand the morphology of streams by the end of the experiment.</li>
</p>
</section>

<!-- Observations -->
<section>
<h2>Observations</h2>
<p>
We observed participants using an iterative modeling process with the tangible interface:
<ul>
  <li>Sculpting</li>
  <li>Studying the updated water flow simulation</li>
  <li>Critiquing the form of their model</li>
  <li>Continuing to sculpt</li>
</ul>
</p>
</section>

<!-- Conclusions -->
<section data-background="img/water_flow.png">
<h2>Conclusion</h2>
<p>Seeing the water flow simulation update in near real-time
enabled participants to generate hypotheses, test hypotheses, and draw inferences
about the way that water flows over topography.</p>
<p>As one participant said, <i>`seeing the flow takes away the mystery of topography.'</i></p>
</section>

<!-- Open source | open science-->
<section>
<h2>Open source | Open science</h2>
<img width="10%" src="img/Octocat.png">
<h4 style="margin-top: 1em">Fork us on GitHub</h4>
<p><a href="https://github.com/baharmon/tangible-water-flow">Repository with experiment instructions, scripts, data, and results</a></p>
<p><a href="https://github.com/ncsu-osgeorel/grass-tangible-landscape">Tangible Landscape plugin for GRASS GIS</a></p>
<p><a href="https://github.com/ncsu-osgeorel/r.in.kinect">GRASS GIS module for importing data from Kinect v2</a></p>
<p><a href="https://osf.io/w8nr6/">Tangible Landscape repository on Open Science Framework</a></p>
</section>

<!-- Future work -->
  <!-- Larger study (with difference analytic) -->
  <!-- Eye tracking and biometrics -->
  <!-- Cognition, affect, motivation, and metacognition -->

<!-- Learn more -->


<!-- Book -->
<section>
<h2>Further reading</h2>
<img width="20%" src="img/tl_book_cover.png">
<p>Read our <a href="http://www.springer.com/us/book/9783319257730">book</a> and give it a try</p>
</section>
