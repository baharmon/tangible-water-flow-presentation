<section>
<h3 style="color: #888"><a href="http://www.isprs2016-prague.com/">ISPRS 2016</a></h3>
<h1 style="margin-top: 0.5em">Tangible Landscape</h1>
<h2 style="margin-top: 0.5em">Cognitively grasping the flow of water</h2>
<h4>Brendan Harmon, Anna Petrasova, Vaclav Petras, Helena Mitasova, &amp; Ross Meentemeyer</h4>
<img height="100px" style="margin-top: 2em" src="img/cgaBlack.png">
</section>

<!-- Tangible Landscape -->
<section data-background="img/tangible_landscape.jpg">
<h1 class="shadow">Tangible Landscape</h1>
<h3 class="shadow">A tangible user interface powered by open source GIS</h3>
<img height="150px" src="img/logo_black.png">
</section>

<!-- Near real time interaction -->
<section>
<h2>Tanigble interaction with GIS</h2>
<video  data-autoplay width="90%" style="margin-top: 1em" controls>
<source src="img/tl_dam.mp4" type="video/mp4">
Your browser does not support the video tag.
</video>
<p>With Tangible Landscape you can hold a GIS in your hands - feeling the shape of the earth, sculpting its topography, and directing the flow of water.</p>
</section>

<!-- History -->
<section>
<h2>History</h2>
<img height="250px" src="img/illuminating_clay.png">
<img height="250px" src="img/tangeoms_2.jpg">
<p>An evolution of <b>Illuminating Clay</b> and the <b>Tangible Geospatial Modeling System</b></p>
<p style="font-size:0.75em"><a href="http://tmg-trackr.media.mit.edu/publishedmedia/Papers/249-Illuminating%20Clay%20A%20Tangible/Published/PDF">Piper, Ben, Carlo Ratti, and Hiroshi Ishii. 2002. “Illuminating Clay: A Tangible Interface with Potential GRASS Applications.” In Proceedings of the Open Source GIS - GRASS Users Conference 2002. Trento, Italy.</a></p>
<p style="font-size:0.75em">Image source: <a href="http://tangible.media.mit.edu/project/illuminating-clay/">MIT Media Lab</a></p>
<p style="font-size:0.75em"><a href="http://baharmon.github.io/publications/tangible_geospatial_modeling.pdf">L. Tateosian, H. Mitasova, B. A. Harmon, B. Fogleman, K. Weaver, and R. S. Harmon, “TanGeoMS: tangible geospatial modeling system.,” IEEE Trans. Vis. Comput. Graph., vol. 16, no. 6, pp. 1605–12, 2010.</a></p>
</section>

<!-- How it works -->
<section>
<h2>How-it-works</h2>
<img style="margin-top: 1em" height="500px" src="img/system_schema.png">
<p>Tangible Landscape couples a digital and a physical model through a continuous cycle of 3D scanning, geospatial modeling, and projection</p>
</section>

<!-- Features -->
<section>
<h2>Features</h2>
<video  data-autoplay width="90%" style="margin-top: 0.5em" controls>
<source src="img/tl_immersion.mp4" type="video/mp4">
Your browser does not support the video tag.
</video>
<p>A collaborative environment for tangible freeform modeling, object detection, real-time geospatial analytics, 3D rendering, and immersion / VR</p>
</section>

<!-- Science with Tangible Landscape -->
<section>
<h2>Intuitive scientific modeling with Tangible Landscape</h2>
<img width="25%" src="img/subsurface_1.jpg">
<img width="25%" src="img/subsurface_2.jpg">
<img width="40.55%" src="img/subsurface_3.jpg">
<p>Tangible Landscape is designed to enable a rapid iterative process of observation, hypothesizing, testing, and inference</p>
</section>

<!-- Experiment -->



<!--
Theoretically a tangible interface for a GIS that enables intuitive digital sculpting while providing analytical
feedback should allow users to dynamically explore how topographic form influences landscape processes.
With a physical model one can
cognitively grasp topographic form,
offloading the cognitive work of
understanding and shaping topographic form onto the body.
A GIS can offload the cognitive work of simulating complex physical processes
like the flow of water through computation.
With these physical and computational affordances combined in a tangible interface for GIS users should be able to more easily understand and shape spatial processes.
-->


<!-- Aim -->
<section>
<h2>Research aim</h2>
<p>How do 3D tangible interfaces for GIS mediate spatial thinking about landscape processes like water flow?</p>
<img height="300px" src="img/tl_system_logo.png">
</section>

<!-- Research questions -->
<section>
<h2>Research questions</h2>
<p>
<ul>
  <li>Can users offload the cognitive work of understanding and shaping topographic form onto the body?</li>
  <li>Can users dynamically explore how topographic form influences landscape processes?</li>
</ul>
</p>
<img height="200px" src="img/tl_logo.png">
</section>

<!-- Design | Methods -->

<!--<section data-background="img/depth_3d.png">-->
<section>
<h2>Experiment</h2>
<img width="50%" src="img/depth_3d.png">
<p>Participants were asked to sculpt a given landscape in 10 minutes using <b>a)</b> a digital modeling program and then <b>b)</b> Tangible Landscape's water flow analytic</p>
<p>Their perfomance was assessed using cellular statistics and hydrological simulation</p>
</section>

<section data-background="img/vue.jpg">
<h1 class="shadow">Vue</h1>
<h3 class="shadow">Terrain editor</h3>
<p class="shadow">3D modeling program designed for intuitive terrain sculpting</p>
</section>

<section data-background="img/tl_water.jpg">
<h1 class="shadow">Tangible Landscape</h1>
<h3 class="shadow">Water flow analytic</h3>
</section>

<!-- r.sim.water -->
<section data-background="img/tl_water.png">
<h2 class="shadow">Water flow simulation</h2>
<h4 class="shadow">A path sampling technique for solving the shallow water flow continuity equation</h4>
<p class="shadow">Implemented in GRASS GIS as the module <a href="https://grass.osgeo.org/grass72/manuals/r.sim.water.html">r.sim.water</a></p>
</section>

<!-- Results -->

<section>
<h2>Elevation</h2>
<img width="30%" src="img/results/render_3d/dem.png">
<img width="30%" src="img/results/render_3d/mean_dem_1.png">
<img width="30%" src="img/results/render_3d/mean_dem_2.png">
<p><b>a)</b> The reference landscape, <b>b)</b> the mean of digitally sculpted models, <b>c)</b> and the mean of tangibly sculpted models</p>
</section>

<section>
<h2>Water flow</h2>
<img width="30%" src="img/results/render_3d/depth.png">
<img width="30%" src="img/results/render_3d/mean_depth_1.png">
<img width="30%" src="img/results/render_3d/mean_depth_2.png">
<p>Water depth on <b>a)</b> the reference landscape, <b>b)</b> the mean of digitally sculpted models, <b>c)</b> and the mean of tangibly sculpted models</p>
</section>

<section>
<h2>Difference in water flow</h2>
<img width="30%" src="img/results/render_3d/diff.png">
<img width="30%" src="img/results/render_3d/mean_diff_1.png">
<img width="30%" src="img/results/render_3d/mean_diff_2.png">
<p>The difference between the reference water depth and <b>a)</b> itself, <b>b)</b> the mean water depth of digitally sculpted models, <b>c)</b> and the mean water depth of tangibly sculpted models</p>
</section>

<!--
<section>
<h2>Minimum distance</h2>
<img width="30%" src="img/results/render_3d/flow_distance_1.png">
<img width="30%" src="img/results/render_3d/flow_distance_2.png">
<p>The minimum distance between points with concentrated flow on the reference landscape and <b>a)</b> the mean of digitally sculpted models <b>b)</b> and the mean of tangibly sculpted models</p>
</section>
-->

<section>
<h2>Depressions</h2>
<img width="30%" src="img/results/render_3d/depressions.png">
<img width="30%" src="img/results/render_3d/mean_depressions_1.png">
<img width="30%" src="img/results/render_3d/mean_depressions_2.png">
<p>The depth of depressions in <b>a)</b> the reference landscape, <b>b)</b> the mean of digitally sculpted models, <b>c)</b> and the mean of tangibly sculpted models</p>
</section>

<section>
<h2>Percent cells with depressions</h2>
<p>
<table>
<tr><th>Exercise</th><th>Cells</th></tr>
<tr><td>Reference</td><td>0%</td></tr>
<tr><td>Digital</td><td>44%</td></tr>
<tr><td>Tangible</td><td>17.66%</td></tr>
</table>
</p>
</section>

<!-- Findings -->
<section>
<h2>Findings</h2>
<h4>Digital modeling</h4>
<p>Participants focused on making streams lower than their surroundings, rather than directing continuous flows</p>
<p>
<ul>
  <li>Diffuse water flow</li>
  <li>Extensive pooling in depressions</li>
</p>
</section>

<!-- Findings -->
<section>
<h2>Findings</h2>
<h4>Tangible modeling</h4>
<p>While most participants did not clearly understand how topography directs water flow at first, they began to learn about curvature and continuity with the aid of the tangible interface</p>
<p>
<ul>
  <li>More accurately replicated the flow of water over the study landscape </li>
  <li>More flow in stream channels</li>
  <li>Less pooling in depressions</li>
  <li>The spatial distribution of water flow more closely fit the reference</li>
</p>
</section>

<!-- Observations -->
<section>
<h2>Observations</h2>
<p>
We observed participants using an iterative modeling process with the tangible interface:
<ul>
  <li>Sculpting</li>
  <li>Studying the updated water flow simulation</li>
  <li>Critiquing the form of their model</li>
  <li>Continuing to sculpt</li>
</ul>
</p>
</section>

<!-- Conclusions -->
<section data-background="img/tl_water.png">
<h2 class="shadow">Conclusions</h2>
<h4 class="shadow">Seeing the water flow simulation update in near real-time
enabled participants to generate hypotheses, test hypotheses, and draw inferences
about the way that water flows over topography.</h4>
<h4 class="shadow">As one participant said, <i>`seeing the flow takes away the mystery of topography.'</i></h4>
</section>

<!-- Open source | open science-->
<section>
<h2>Open source | Open science</h2>
<img width="10%" src="img/Octocat.png">
<h4 style="margin-top: 1em">Fork us on GitHub</h4>
<p><a href="https://grass.osgeo.org/">GRASS GIS</a></p>
<p><a href="https://github.com/tangible-landscape/grass-tangible-landscape">Tangible Landscape plugin for GRASS GIS</a></p>
<p><a href="https://github.com/tangible-landscape/r.in.kinect">GRASS GIS module for importing data from Kinect v2</a></p>
<p><a href="https://github.com/baharmon/tangible-water-flow">Repository with experiment instructions, scripts, data, and results</a></p>
<p><a href="https://osf.io/zv3t6/">Experiment repository on Open Science Framework</a></p>
</section>

<!-- Future work -->
<section data-background="img/tl_cog_sci_150dpi.png">
<h2 class="inverse">Future work</h1>
<!-- Larger study with morphometric analyses -->
<!-- Eye tracking and biometrics -->
<!-- Cognition, affect, motivation, and metacognition -->
</section>

<!-- Book -->
<section>
<h2>Learn more</h2>
<img width="20%" src="img/tl_book_cover.png">
<p>Read our <a href="http://www.springer.com/us/book/9783319257730">book</a>
or visit our website at <a href="http://tangible-landscape.github.io/">http://tangible-landscape.github.io/</a>
and give it a try</p>
</section>
